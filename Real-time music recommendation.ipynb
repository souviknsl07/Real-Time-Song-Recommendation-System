{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "700efc81-1c97-45fa-98c4-a958029234dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.ml.recommendation.ALSModel\n",
    "\n",
    "// Define schema\n",
    "val schema = StructType(Array(\n",
    "  StructField(\"user_id\", IntegerType),\n",
    "  StructField(\"user_name\", StringType),\n",
    "  StructField(\"track_id\", IntegerType),\n",
    "  StructField(\"like\", IntegerType),\n",
    "  StructField(\"timestamp\", DoubleType)\n",
    "))\n",
    "\n",
    "val aws_access_key = dbutils.secrets.get(scope=\"aws\", key=\"aws-access-key-id\")\n",
    "val aws_secret_key = dbutils.secrets.get(scope=\"aws\", key=\"aws-secret-access-key\")\n",
    "\n",
    "// Set AWS credentials\n",
    "spark.sparkContext.hadoopConfiguration.set(\"fs.s3a.access.key\", aws_access_key)\n",
    "spark.sparkContext.hadoopConfiguration.set(\"fs.s3a.secret.key\", aws_secret_key)\n",
    "spark.sparkContext.hadoopConfiguration.set(\"fs.s3a.endpoint\", \"s3.amazonaws.com\")\n",
    "\n",
    "// Load ALS model\n",
    "val alsModel = ALSModel.load(\"s3a://souvik-dev-stage/ALSModel\")\n",
    "\n",
    "// Read raw streaming text data from S3\n",
    "val rawImpressions = spark.readStream\n",
    "  .format(\"text\")\n",
    "  .option(\"wholeText\", \"true\")\n",
    "  .option(\"checkpointLocation\", \"s3a://souvik-dev-stage/checkpoint_new_events/\")\n",
    "  .load(\"s3a://souvik-dev-stage/music-user-impressions/2025/05/08/20/\")\n",
    "\n",
    "// Split concatenated JSON objects using regex and explode\n",
    "val splitJsons = rawImpressions.select(\n",
    "  explode(\n",
    "    split(col(\"value\"), \"\"\"(?<=\\})(?=\\{)\"\"\")\n",
    "  ).alias(\"json_str\")\n",
    ")\n",
    "\n",
    "// Parse the JSON and add event_date column\n",
    "val parsedImpressions = splitJsons\n",
    "  .select(from_json(col(\"json_str\"), schema).alias(\"data\"))\n",
    "  .select(\"data.*\")\n",
    "  .withColumn(\"event_date\", to_date(from_unixtime(col(\"timestamp\"))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b97bd90-4ac5-43b3-9fb4-b164aff89813",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "import org.apache.spark.ml.recommendation.ALSModel\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.expressions.Window\n",
    "import org.apache.spark.sql.streaming.Trigger\n",
    "\n",
    "// Load pre-trained ALS model\n",
    "val alsModel = ALSModel.load(\"s3a://souvik-dev-stage/ALSModel\")\n",
    "\n",
    "// Get distinct users from the parsed impressions\n",
    "val users = parsedImpressions.select(\"user_id\", \"event_date\").distinct()\n",
    "\n",
    "// Get top 5 recommendations for all users\n",
    "val recommendations = alsModel.recommendForAllUsers(5)\n",
    "\n",
    "// Flatten the recommendation array and extract fields\n",
    "val flattened = recommendations\n",
    "  .withColumn(\"rec\", explode(col(\"recommendations\")))\n",
    "  .select(\n",
    "    col(\"user_id\"),\n",
    "    col(\"rec.track_id\").alias(\"track_id\"),\n",
    "    col(\"rec.rating\").alias(\"rating\")\n",
    "  )\n",
    "\n",
    "// Define window spec for ranking\n",
    "val windowSpec = Window.partitionBy(\"user_id\").orderBy(col(\"rating\").desc)\n",
    "\n",
    "// Add ranking\n",
    "val ranked = flattened\n",
    "  .withColumn(\"rank\", row_number().over(windowSpec))\n",
    "\n",
    "// Enrich with event_date (join with original user list)\n",
    "val enriched = users.join(ranked, Seq(\"user_id\"), \"leftsemi\")\n",
    "  .select(\"user_id\", \"track_id\", \"rating\", \"rank\", \"event_date\")\n",
    "\n",
    "// Write to S3 with partition by event_date\n",
    "enriched.writeStream\n",
    "  .format(\"parquet\")\n",
    "  .outputMode(\"append\")\n",
    "  .partitionBy(\"event_date\")\n",
    "  .option(\"path\", \"s3a://souvik-dev-stage/user_recommendations/collaborative/\")\n",
    "  .option(\"checkpointLocation\", \"s3a://souvik-dev-stage/checkpoint_recommendation/collaborative/\")\n",
    "  .trigger(Trigger.Once())\n",
    "  .start()\n",
    "  .awaitTermination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c288e00-783f-46cc-8085-84edd4036fb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "val new_data = parsedImpressions.select(\"user_id\", \"track_id\", \"like\")\n",
    "\n",
    "new_data.writeStream \n",
    "    .format(\"csv\") \n",
    "    .outputMode(\"append\") \n",
    "    .option(\"path\", \"s3a://souvik-dev-stage/new_user_data/\") \n",
    "    .option(\"checkpointLocation\", \"s3a://souvik-dev-stage/checkpoint_new_data/\") \n",
    "    .option(\"header\", \"true\")\n",
    "    .trigger(Trigger.Once()) \n",
    "    .start() \n",
    "    .awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02bc464d-c0f5-4de7-aa9c-1de02cf5d31e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# out = spark.read.parquet('s3a://souvik-dev-stage/user_recommendations/')\n",
    "# out.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7f55a4a-0db2-44f0-b8b9-6a75526fd146",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Content based recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3248a7a-4c44-42d9-8752-a9ab35ed3ea1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "val user_likes = parsedImpressions.select(\"user_id\", \"track_id\", \"event_date\")\n",
    "val likedItems = user_likes.join(itemsFeaturized, \"track_id\")\n",
    "val likedVectors = likedItems\n",
    "  .groupBy(\"user_id\")\n",
    "  .agg(collect_list($\"features\").as(\"featureList\"))\n",
    "display(likedVectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ee5d5d2-5c68-4117-8ca5-fb1c58ade0bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "\n",
    "val itemsFeaturized = spark.read.option(\"header\", \"true\")\n",
    "    .parquet(\"s3a://souvik-dev-stage/contentModel/\")\n",
    "\n",
    "val user_likes = parsedImpressions\n",
    "                .withColumn(\"event_time\", to_timestamp(from_unixtime(col(\"timestamp\"))))\n",
    "                .withWatermark(\"event_time\", \"10 minutes\")\n",
    "                .select(\"user_id\", \"track_id\", \"event_date\", \"event_time\")\n",
    "\n",
    "val likedItems = user_likes.join(itemsFeaturized, \"track_id\")\n",
    "\n",
    "import org.apache.spark.ml.linalg.{Vector, Vectors}\n",
    "import breeze.linalg.{DenseVector => BDV}\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val avgVectorUDF = udf((vectors: Seq[Vector]) => {\n",
    "  val breezeVecs = vectors.map(v => BDV(v.toArray))\n",
    "  val sumVec = breezeVecs.reduce(_ + _)\n",
    "  val avgVec = sumVec / breezeVecs.length.toDouble\n",
    "  Vectors.dense(avgVec.toArray)\n",
    "})\n",
    "\n",
    "val likedVectors = likedItems\n",
    "  .groupBy(\"user_id\", \"event_date\", \"event_time\")\n",
    "  .agg(collect_list($\"features\").as(\"featureList\"))\n",
    "\n",
    "val userProfile = likedVectors\n",
    "  .withColumn(\"userFeatures\", avgVectorUDF($\"featureList\"))\n",
    "\n",
    "import org.apache.spark.ml.linalg.Vector\n",
    "import breeze.linalg.{DenseVector => BreezeDenseVector, norm}\n",
    "\n",
    "val cosineSimilarity = udf { (vec1: Vector, vec2: Vector) =>\n",
    "  val v1 = BreezeDenseVector(vec1.toArray)\n",
    "  val v2 = BreezeDenseVector(vec2.toArray)\n",
    "  val dot = v1.dot(v2)\n",
    "  val normProduct = norm(v1) * norm(v2)\n",
    "  if (normProduct == 0.0) 0.0 else dot / normProduct\n",
    "}\n",
    "\n",
    "val cbRecs = itemsFeaturized\n",
    "  .crossJoin(userProfile)\n",
    "  .withColumn(\"cb_score\", cosineSimilarity($\"features\", $\"userFeatures\"))\n",
    "  // .withColumn(\"event_time\", col(\"event_date\").cast(\"timestamp\"))\n",
    "  .select(\"user_id\", \"track_id\", \"track_name\", \"cb_score\", \"event_date\")\n",
    "\n",
    "\n",
    "import org.apache.spark.sql.expressions.Window\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "\n",
    "// Define window partitioned by user_id, ordered by score descending\n",
    "// val windowSpec = Window.partitionBy(\"user_id\").orderBy(col(\"cb_score\").desc)\n",
    "\n",
    "// //Add row number per user\n",
    "// val rankedRecs = cbRecs\n",
    "//   .withColumn(\"rank\", row_number().over(windowSpec))\n",
    "//   .filter(col(\"rank\") <= 5)  // Keep only top 5 per user\n",
    "//   .select(\"user_id\", \"track_id\", \"track_name\", \"cb_score\", \"rank\", \"event_date\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9acb7c14-e7f1-4cbc-a89e-9118e68af484",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "cbRecs.writeStream\n",
    "  .format(\"parquet\")\n",
    "  .outputMode(\"append\")\n",
    "  .partitionBy(\"event_date\")\n",
    "  .option(\"path\", \"s3a://souvik-dev-stage/user_recommendations/content_based/\")\n",
    "  .option(\"checkpointLocation\", \"s3a://souvik-dev-stage/checkpoint_recommendation/content_based/\")\n",
    "  .trigger(Trigger.Once())\n",
    "  .start()\n",
    "  .awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b10d80aa-14aa-4a6a-ac59-11eb2b9218d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "//Creating hybrid model\n",
    "\n",
    "val alsRecs = alsModel.recommendForAllUsers(5)\n",
    "  .withColumn(\"rec\", explode($\"recommendations\"))\n",
    "  .select($\"user_id\", $\"rec.track_id\".as(\"track_id\"), $\"rec.rating\".as(\"als_score\"))\n",
    "\n",
    "val alpha = 0.7  // weight for ALS; (1 - alpha) for CB\n",
    "\n",
    "val tracks = itemsFeaturized.select(\"track_id\", \"track_name\")\n",
    "\n",
    "val hybrid = cbRecs.join(alsRecs, Seq(\"user_id\", \"track_id\"), \"left\")\n",
    "  .na.fill(0.0, Seq(\"als_score\", \"cb_score\"))\n",
    "  .withColumn(\"hybrid_score\", $\"als_score\" * alpha + $\"cb_score\" * (1 - alpha))\n",
    "  .join(tracks, \"track_id\")\n",
    "  .select(\"user_id\", \"track_id\", \"track_name\", \"hybrid_score\", \"event_date\")\n",
    "  .orderBy($\"user_id\", $\"hybrid_score\".desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3ab2fd9-e207-497c-852b-dc4d0821e4f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "hybrid.writeStream\n",
    "  .format(\"parquet\")\n",
    "  .outputMode(\"append\")\n",
    "  .partitionBy(\"event_date\")\n",
    "  .option(\"path\", \"s3a://souvik-dev-stage/user_recommendations/hybrid/\")\n",
    "  .option(\"checkpointLocation\", \"s3a://souvik-dev-stage/checkpoint_recommendation/hybrid/\")\n",
    "  .trigger(Trigger.Once())\n",
    "  .start()\n",
    "  .awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 770156792713982,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Real-time music recommendation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
